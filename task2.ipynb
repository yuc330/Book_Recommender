{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.io import arff\n",
    "from io import StringIO\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "import random\n",
    "from scipy.stats import pearsonr\n",
    "from collections import defaultdict\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "from nltk.stem.porter import *\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "def parseData(fname):\n",
    "    for l in open(fname):\n",
    "        yield eval(l)\n",
    "\n",
    "def parseDataFromURL(fname):\n",
    "    for l in urlopen(fname):\n",
    "        yield eval(l)\n",
    "\n",
    "### Just the first 5000 reviews\n",
    "\n",
    "print(\"Reading data...\")\n",
    "data = list(parseData(\"train_Category.json\"))\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation = set(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews['review_text'] = reviews['review_text'].apply(lambda x: ''.join([c for c in x.lower() if (not c in punctuation)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews['review_text'] = reviews['review_text'].apply(lambda x: ' '.join(w for w in x.split() if not w in stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.base import TransformerMixin, BaseEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_feat = ['user_id']\n",
    "user_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown = 'ignore'))\n",
    "])\n",
    "\n",
    "text_feat = ['review_text']\n",
    "text_transformer = Pipeline(steps=[\n",
    "    ('tfidf', TfidfVectorizer(analyzer='word', stop_words='english'))\n",
    "])\n",
    "\n",
    "X = reviews[['user_id', 'review_text']][:190000]\n",
    "y = reviews.genreID[:190000]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ItemSelector(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, data_dict):\n",
    "        return data_dict[self.key]\n",
    "\n",
    "pl = Pipeline([\n",
    "        ('union', FeatureUnion(\n",
    "            transformer_list=[\n",
    "                ('text', Pipeline([\n",
    "                    ('selector', ItemSelector(key='review_text')),\n",
    "                    ('tfidf', text_transformer),\n",
    "                ])),\n",
    "                ('user', Pipeline([\n",
    "                    #('selector', ItemSelector(key='user_id')),\n",
    "                    ('onehot', user_transformer),\n",
    "                ])),\n",
    "            ]\n",
    "        )),\n",
    "        ('model', LogisticRegression(C=10)),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('union',\n",
       "                 FeatureUnion(n_jobs=None,\n",
       "                              transformer_list=[('text',\n",
       "                                                 Pipeline(memory=None,\n",
       "                                                          steps=[('selector',\n",
       "                                                                  ItemSelector(key='review_text')),\n",
       "                                                                 ('tfidf',\n",
       "                                                                  Pipeline(memory=None,\n",
       "                                                                           steps=[('tfidf',\n",
       "                                                                                   TfidfVectorizer(analyzer='word',\n",
       "                                                                                                   binary=False,\n",
       "                                                                                                   decode_error='strict',\n",
       "                                                                                                   dtype=<class 'numpy.float64'>,\n",
       "                                                                                                   encoding='utf-8',\n",
       "                                                                                                   input='content',\n",
       "                                                                                                   lowercase=True...\n",
       "                                                                                                 n_values=None,\n",
       "                                                                                                 sparse=True))],\n",
       "                                                                           verbose=False))],\n",
       "                                                          verbose=False))],\n",
       "                              transformer_weights=None, verbose=False)),\n",
       "                ('model',\n",
       "                 LogisticRegression(C=10, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='warn', n_jobs=None,\n",
       "                                    penalty='l2', random_state=None,\n",
       "                                    solver='warn', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8033"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.score(reviews[['user_id', 'review_text']][190000:], reviews.genreID[190000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = list(parseData(\"test_Category.json\"))\n",
    "test = pd.DataFrame(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['review_text'] = test['review_text'].apply(lambda x: ''.join([c for c in x.lower() if (not c in punctuation)]))\n",
    "test['review_text'] = test['review_text'].apply(lambda x: ' '.join(w for w in x.split() if not w in stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pl.predict(test[['user_id', 'review_text']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = [d['user_id'] + '-' + d['review_id'] for d in data_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_genre = open(\"predictions_genre.txt\", 'w')\n",
    "prediction_genre.write(\"userID-reviewID,prediction\\n\")\n",
    "for i in range(10000):\n",
    "    prediction_genre.write(ids[i] + \",\" + str(pred[i]) + \"\\n\")\n",
    "    \n",
    "\n",
    "prediction_genre.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kaggle username: winniecyc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
